{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_sparse_data_and_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "mNCLhxsXyOIS",
        "eQS5KQzBybTY"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nikhilbhatewara/GoogleMachineLearningCrashCourse/blob/master/intro_to_sparse_data_and_embeddings.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTaAdgy3LS8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro to Sparse Data and Embeddings\n",
        "\n",
        "**Learning Objectives:**\n",
        "* Convert movie-review string data to a sparse feature vector\n",
        "* Implement a sentiment-analysis linear model using a sparse feature vector\n",
        "* Implement a sentiment-analysis DNN model using an embedding that projects data into two dimensions\n",
        "* Visualize the embedding to see what the model has learned about the relationships between words\n",
        "\n",
        "In this exercise, we'll explore sparse data and work with embeddings using text data from movie reviews (from the [ACL 2011 IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/)). This data has already been processed into `tf.Example` format.  "
      ]
    },
    {
      "metadata": {
        "id": "2AKGtmwNosU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Let's import our dependencies and download the training and test data. [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) includes a file download and caching tool that we can use to retrieve the data sets."
      ]
    },
    {
      "metadata": {
        "id": "jGWqDqFFL_NZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "510e5faa-d101-4dfd-def8-c31309f7fe3b"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord\n",
            "41631744/41625533 [==============================] - 8s 0us/step\n",
            "41639936/41625533 [==============================] - 8s 0us/step\n",
            "Downloading data from https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord\n",
            "40689664/40688441 [==============================] - 1s 0us/step\n",
            "40697856/40688441 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6W7aZ9qspZVj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a Sentiment Analysis Model"
      ]
    },
    {
      "metadata": {
        "id": "jieA0k_NLS8a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's train a sentiment-analysis model on this data that predicts if a review is generally *favorable* (label of 1) or *unfavorable* (label of 0).\n",
        "\n",
        "To do so, we'll turn our string-value `terms` into feature vectors by using a *vocabulary*, a list of each term we expect to see in our data. For the purposes of this exercise, we've created a small vocabulary that focuses on a limited set of terms. Most of these terms were found to be strongly indicative of *favorable* or *unfavorable*, but some were just added because they're interesting.\n",
        "\n",
        "Each term in the vocabulary is mapped to a coordinate in our feature vector. To convert the string-value `terms` for an example into this vector format, we encode such that each coordinate gets a value of 0 if the vocabulary term does not appear in the example string, and a value of 1 if it does. Terms in an example that don't appear in the vocabulary are thrown away."
      ]
    },
    {
      "metadata": {
        "id": "2HSfklfnLS8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** *We could of course use a larger vocabulary, and there are special tools for creating these. In addition, instead of just dropping terms that are not in the vocabulary, we can introduce a small number of OOV (out-of-vocabulary) buckets to which you can hash the terms not in the vocabulary. We can also use a __feature hashing__ approach that hashes each term, instead of creating an explicit vocabulary. This works well in practice, but loses interpretability, which is useful for this exercise. See see the tf.feature_column module for tools handling this.*"
      ]
    },
    {
      "metadata": {
        "id": "Uvoa2HyDtgqe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building the Input Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "O20vMEOurDol",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's configure the input pipeline to import our data into a TensorFlow model. We can use the following function to parse the training and test data (which is in [TFRecord](https://www.tensorflow.org/programmers_guide/datasets) format) and return a dict of the features and the corresponding labels."
      ]
    },
    {
      "metadata": {
        "id": "SxxNIEniPq2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return  {'terms':terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SXhTeeYMrp-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To confirm our function is working as expected, let's construct a `TFRecordDataset` for the training data, and map the data to features and labels using the function above."
      ]
    },
    {
      "metadata": {
        "id": "oF4YWXR0Omt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1add2697-4d42-426a-f24b-cc128f215330"
      },
      "cell_type": "code",
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)\n",
        "\n",
        "ds"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "bUoMvK-9tVXP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following cell to retrieve the first example from the training data set."
      ]
    },
    {
      "metadata": {
        "id": "Z6QE2DWRUc4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "a4e96a5d-a176-448c-bc9c-f0870e42dd65"
      },
      "cell_type": "code",
      "source": [
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()\n",
        "sess.run(n)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'terms': array(['but', 'it', 'does', 'have', 'some', 'good', 'action', 'and', 'a',\n",
              "         'plot', 'that', 'is', 'somewhat', 'interesting', '.', 'nevsky',\n",
              "         'acts', 'like', 'a', 'body', 'builder', 'and', 'he', 'isn', \"'\",\n",
              "         't', 'all', 'that', 'attractive', ',', 'in', 'fact', ',', 'imo',\n",
              "         ',', 'he', 'is', 'ugly', '.', '(', 'his', 'acting', 'skills',\n",
              "         'lack', 'everything', '!', ')', 'sascha', 'is', 'played', 'very',\n",
              "         'well', 'by', 'joanna', 'pacula', ',', 'but', 'she', 'needed',\n",
              "         'more', 'lines', 'than', 'she', 'was', 'given', ',', 'her',\n",
              "         'character', 'needed', 'to', 'be', 'developed', '.', 'there',\n",
              "         'are', 'way', 'too', 'many', 'men', 'in', 'this', 'story', ',',\n",
              "         'there', 'is', 'zero', 'romance', ',', 'too', 'much', 'action',\n",
              "         ',', 'and', 'way', 'too', 'dumb', 'of', 'an', 'ending', '.', 'it',\n",
              "         'is', 'very', 'violent', '.', 'i', 'did', 'however', 'love', 'the',\n",
              "         'scenery', ',', 'this', 'movie', 'takes', 'you', 'all', 'over',\n",
              "         'the', 'world', ',', 'and', 'that', 'is', 'a', 'bonus', '.', 'i',\n",
              "         'also', 'liked', 'how', 'it', 'had', 'some', 'stuff', 'about',\n",
              "         'the', 'mafia', 'in', 'it', ',', 'not', 'too', 'much', 'or', 'too',\n",
              "         'little', ',', 'but', 'enough', 'that', 'it', 'got', 'my',\n",
              "         'attention', '.', 'the', 'actors', 'needed', 'to', 'be', 'more',\n",
              "         'handsome', '.', '.', '.', 'the', 'biggest', 'problem', 'i', 'had',\n",
              "         'was', 'that', 'nevsky', 'was', 'just', 'too', 'normal', ',',\n",
              "         'not', 'sexy', 'enough', '.', 'i', 'think', 'for', 'most', 'guys',\n",
              "         ',', 'sascha', 'will', 'be', 'hot', 'enough', ',', 'but', 'for',\n",
              "         'us', 'ladies', 'that', 'are', 'fans', 'of', 'action', ',',\n",
              "         'nevsky', 'just', 'doesn', \"'\", 't', 'cut', 'it', '.', 'overall',\n",
              "         ',', 'this', 'movie', 'was', 'fine', ',', 'i', 'didn', \"'\", 't',\n",
              "         'love', 'it', 'nor', 'did', 'i', 'hate', 'it', ',', 'just',\n",
              "         'found', 'it', 'to', 'be', 'another', 'normal', 'action', 'flick',\n",
              "         '.'], dtype=object)}, array([0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "jBU39UeFty9S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's build a formal input function that we can pass to the `train()` method of a TensorFlow Estimator object."
      ]
    },
    {
      "metadata": {
        "id": "5_C5-ueNYIn_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an input_fn that parses the tf.Examples from the given files,\n",
        "# and split them into features and targets.\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "  \n",
        "  # Same code as above; create a dataset and map features and labels.\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  # Our feature data is variable-length, so we pad and batch\n",
        "  # each field of the dataset structure to whatever size is necessary.\n",
        "  ds = ds.padded_batch(25, ds.output_shapes)\n",
        "  \n",
        "  ds = ds.repeat(num_epochs)\n",
        "\n",
        "  \n",
        "  # Return the next batch of data.\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y170tVlrLS8c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Use a Linear Model with Sparse Inputs and an Explicit Vocabulary\n",
        "\n",
        "For our first model, we'll build a [`LinearClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) model using 50 informative terms; always start simple!\n",
        "\n",
        "The following code constructs the feature column for our terms. The [`categorical_column_with_vocabulary_list`](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list) function creates a feature column with the string-to-feature-vector mapping."
      ]
    },
    {
      "metadata": {
        "id": "B5gdxuWsvPcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 50 informative terms that compose our model vocabulary \n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eTiDwyorwd3P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll construct the `LinearClassifier`, train it on the training set, and evaluate it on the evaluation set. After you read through the code, run it and see how you do."
      ]
    },
    {
      "metadata": {
        "id": "HYKKpGLqLS8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "be0f3eec-0732-44e7-d4c8-bdec2593a170"
      },
      "cell_type": "code",
      "source": [
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [ terms_feature_column ]\n",
        "\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 11.254127\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.8304\n",
            "auc 0.8725448\n",
            "prediction/mean 0.49632794\n",
            "precision 0.7675244\n",
            "label/mean 0.5\n",
            "average_loss 0.4501651\n",
            "auc_precision_recall 0.8642721\n",
            "accuracy 0.78944\n",
            "---\n",
            "Test set metrics:\n",
            "loss 11.292676\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.82328\n",
            "auc 0.87030643\n",
            "prediction/mean 0.49512678\n",
            "precision 0.76467526\n",
            "label/mean 0.5\n",
            "average_loss 0.45170704\n",
            "auc_precision_recall 0.86188954\n",
            "accuracy 0.78496\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J0ubn9gULS8g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Use a Deep Neural Network (DNN) Model\n",
        "\n",
        "The above model is a linear model.  It works quite well.  But can we do better with a DNN model?\n",
        "\n",
        "Let's swap in a [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) for the `LinearClassifier`. Run the following cell, and see how you do."
      ]
    },
    {
      "metadata": {
        "id": "jcgOPfEALS8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "15e85975-8235-4b82-f144-1ee370181371"
      },
      "cell_type": "code",
      "source": [
        "##################### Here's what we changed ##################################\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000)\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1)\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([test_path]),\n",
        "    steps=1)\n",
        "\n",
        "  print(\"Test set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 8.598821\n",
            "accuracy_baseline 0.56\n",
            "global_step 1000\n",
            "recall 0.90909094\n",
            "auc 0.9318181\n",
            "prediction/mean 0.46322602\n",
            "precision 0.8333333\n",
            "label/mean 0.44\n",
            "average_loss 0.34395283\n",
            "auc_precision_recall 0.8914732\n",
            "accuracy 0.88\n",
            "---\n",
            "Test set metrics:\n",
            "loss 7.8335085\n",
            "accuracy_baseline 0.6\n",
            "global_step 1000\n",
            "recall 0.8\n",
            "auc 0.95999986\n",
            "prediction/mean 0.47906968\n",
            "precision 0.85714287\n",
            "label/mean 0.6\n",
            "average_loss 0.31334034\n",
            "auc_precision_recall 0.9740943\n",
            "accuracy 0.8\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cZz68luxLS8j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Use an Embedding with a DNN Model\n",
        "\n",
        "In this task, we'll implement our DNN model using an embedding column. An embedding column takes sparse data as input and returns a lower-dimensional dense vector as output."
      ]
    },
    {
      "metadata": {
        "id": "AliRzhvJLS8k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** *An embedding_column is usually the computationally most efficient option to use for training a model on sparse data. In an [optional section](#scrollTo=XDMlGgRfKSVz) at the end of this exercise, we'll discuss in more depth the implementational differences between using an `embedding_column` and an `indicator_column`, and the tradeoffs of selecting one over the other.*"
      ]
    },
    {
      "metadata": {
        "id": "F-as3PtALS8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the following code, do the following:\n",
        "\n",
        "* Define the feature columns for the model using an `embedding_column` that projects the data into 2 dimensions (see the [TF docs](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) for more details on the function signature for `embedding_column`).\n",
        "* Define a `DNNClassifier` with the following specifications:\n",
        "  * Two hidden layers of 20 units each\n",
        "  * Adagrad optimization with a learning rate of 0.1\n",
        "  * A `gradient_clip_norm` of 5.0"
      ]
    },
    {
      "metadata": {
        "id": "UlPZ-Q9bLS8m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** *In practice, we might project to dimensions higher than 2, like 50 or 100.  But for now, 2 dimensions is easy to visualize.*"
      ]
    },
    {
      "metadata": {
        "id": "mNCLhxsXyOIS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hint"
      ]
    },
    {
      "metadata": {
        "id": "L67xYD7hLS8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Here's a example code snippet you might use to define the feature columns:\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iv1UBsJxyV37",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Complete the Code Below"
      ]
    },
    {
      "metadata": {
        "id": "5PG_yhNGLS8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1679
        },
        "outputId": "d412b10b-14b6-4ee8-e77a-f8395bc5b97b"
      },
      "cell_type": "code",
      "source": [
        "########################## YOUR CODE HERE ######################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=[tf.feature_column.indicator_column(terms_embedding_column)], #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")     \n",
        "################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d826c900c10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m classifier.train(\n\u001b[1;32m     12\u001b[0m   \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   steps=1000)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m evaluation_metrics = classifier.evaluate(\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1211\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1212\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.pyc\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    383\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m           batch_norm=batch_norm)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     super(DNNClassifier, self).__init__(\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.pyc\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[0;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, tpu_estimator_spec, batch_norm)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         batch_norm=batch_norm)\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpu_estimator_spec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.pyc\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m     92\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[1;32m     93\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[0;32m---> 94\u001b[0;31m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       with variable_scope.variable_scope(\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36minput_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[1;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[0;32m--> 277\u001b[0;31m                                trainable, cols_to_vars)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             trainable=trainable)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m     \u001b[0;31m# representation created by _transform_feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m   def _get_sequence_dense_tensor(\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36m_transform_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mknown\u001b[0m \u001b[0mat\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mbuilding\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     \"\"\"\n\u001b[0;32m-> 3257\u001b[0;31m     \u001b[0mid_weight_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3258\u001b[0m     \u001b[0mid_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_weight_pair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m     \u001b[0mweight_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_weight_pair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_EmbeddingColumn' object has no attribute '_get_sparse_tensors'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eQS5KQzBybTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a solution."
      ]
    },
    {
      "metadata": {
        "id": "R5xOdYeQydi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "cc55cd4e-4ac2-4514-ba74-3cf79fe85582"
      },
      "cell_type": "code",
      "source": [
        "########################## SOLUTION CODE ########################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "#################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 11.3022995\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.78968\n",
            "auc 0.8693199\n",
            "prediction/mean 0.48839164\n",
            "precision 0.786158\n",
            "label/mean 0.5\n",
            "average_loss 0.452092\n",
            "auc_precision_recall 0.8575864\n",
            "accuracy 0.78744\n",
            "---\n",
            "Test set metrics:\n",
            "loss 11.327156\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.7824\n",
            "auc 0.8686478\n",
            "prediction/mean 0.48829624\n",
            "precision 0.7830891\n",
            "label/mean 0.5\n",
            "average_loss 0.45308626\n",
            "auc_precision_recall 0.85682565\n",
            "accuracy 0.78284\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aiHnnVtzLS8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 4: Convince yourself there's actually an embedding in there\n",
        "\n",
        "The above model used an `embedding_column`, and it seemed to work, but this doesn't tell us much about what's going on internally. How can we check that the model is actually using an embedding inside?\n",
        "\n",
        "To start, let's look at the tensors in the model:"
      ]
    },
    {
      "metadata": {
        "id": "h1jNgLdQLS8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "aba8486b-bb3e-42ff-c8e7-09f2a1e2b3f5"
      },
      "cell_type": "code",
      "source": [
        "classifier.get_variable_names()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dnn/hiddenlayer_0/bias',\n",
              " 'dnn/hiddenlayer_0/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_0/kernel',\n",
              " 'dnn/hiddenlayer_0/kernel/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/bias',\n",
              " 'dnn/hiddenlayer_1/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/kernel',\n",
              " 'dnn/hiddenlayer_1/kernel/t_0/Adagrad',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights/t_0/Adagrad',\n",
              " 'dnn/logits/bias',\n",
              " 'dnn/logits/bias/t_0/Adagrad',\n",
              " 'dnn/logits/kernel',\n",
              " 'dnn/logits/kernel/t_0/Adagrad',\n",
              " 'global_step']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Sl4-VctMLS8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Okay, we can see that there is an embedding layer in there: `'dnn/input_from_feature_columns/input_layer/terms_embedding/...'`. (What's interesting here, by the way, is that this layer is trainable along with the rest of the model just as any hidden layer is.)\n",
        "\n",
        "Is the embedding layer the correct shape? Run the following code to find out."
      ]
    },
    {
      "metadata": {
        "id": "JNFxyQUiLS80",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** *Remember, in our case, the embedding is a matrix that allows us to project a 50-dimensional vector down to 2 dimensions.*"
      ]
    },
    {
      "metadata": {
        "id": "1xMbpcEjLS80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b4941e1-b9f9-4755-b8cc-c91563d115f6"
      },
      "cell_type": "code",
      "source": [
        "classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights').shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "MnLCIogjLS82",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Spend some time manually checking the various layers and shapes to make sure everything is connected the way you would expect it would be."
      ]
    },
    {
      "metadata": {
        "id": "rkKAaRWDLS83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 5: Examine the Embedding\n",
        "\n",
        "Let's now take a look at the actual embedding space, and see where the terms end up in it. Do the following:\n",
        "1. Run the following code to see the embedding we trained in **Task 3**. Do things end up where you'd expect?\n",
        "\n",
        "2. Re-train the model by rerunning the code in **Task 3**, and then run the embedding visualization below again. What stays the same? What changes?\n",
        "\n",
        "3. Finally, re-train the model again using only 10 steps (which will yield a terrible model). Run the embedding visualization below again. What do you see now, and why?"
      ]
    },
    {
      "metadata": {
        "id": "s4NNu7KqLS84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "eae0520f-96db-43bb-f548-168d24e83873"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "embedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')\n",
        "\n",
        "for term_index in range(len(informative_terms)):\n",
        "  # Create a one-hot encoding for our term. It has 0s everywhere, except for\n",
        "  # a single 1 in the coordinate that corresponds to that term.\n",
        "  term_vector = np.zeros(len(informative_terms))\n",
        "  term_vector[term_index] = 1\n",
        "  # We'll now project that one-hot vector into the embedding space.\n",
        "  embedding_xy = np.matmul(term_vector, embedding_matrix)\n",
        "  plt.text(embedding_xy[0],\n",
        "           embedding_xy[1],\n",
        "           informative_terms[term_index])\n",
        "\n",
        "# Do a little setup to make sure the plot displays nicely.\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
        "plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.show() "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAANOCAYAAABp/V9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncgQ3AAAAADA5ghsAAAAAmNz/BycjqJmnYEcsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fecfe0fa650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pUb3L7pqLS86",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 6:  Try to improve the model's performance\n",
        "\n",
        "See if you can refine the model to improve performance. A couple things you may want to try:\n",
        "\n",
        "* **Changing hyperparameters**, or **using a different optimizer** like Adam (you may only gain one or two accuracy percentage points following these strategies).\n",
        "* **Adding additional terms to `informative_terms`.** There's a full vocabulary file with all 30,716 terms for this data set that you can use at: https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt You can pick out additional terms from this vocabulary file, or use the whole thing via the `categorical_column_with_vocabulary_file` feature column."
      ]
    },
    {
      "metadata": {
        "id": "6-b3BqXvLS86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f12bcdbf-086f-4a27-e8ab-d8df298e9d30"
      },
      "cell_type": "code",
      "source": [
        "# Download the vocabulary file.\n",
        "terms_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt'\n",
        "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt\n",
            "253952/253538 [==============================] - 0s 0us/step\n",
            "262144/253538 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0jbJlwW5LS8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4ba22d45-5d09-495f-dbef-f12d90446340"
      },
      "cell_type": "code",
      "source": [
        "# Create a feature column from \"terms\", using a full vocabulary file.\n",
        "informative_terms = None\n",
        "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
        "  # Convert it to a set first to remove duplicates.\n",
        "  informative_terms = list(set(f.read().split()))\n",
        "  \n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", \n",
        "                                                                                 vocabulary_list=informative_terms)\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[10,10],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 17.307234\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.12944\n",
            "auc 0.56654525\n",
            "prediction/mean 0.4951666\n",
            "precision 0.6340125\n",
            "label/mean 0.5\n",
            "average_loss 0.69228935\n",
            "auc_precision_recall 0.568458\n",
            "accuracy 0.52736\n",
            "---\n",
            "Test set metrics:\n",
            "loss 17.30946\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.1364\n",
            "auc 0.5547152\n",
            "prediction/mean 0.49532402\n",
            "precision 0.62022555\n",
            "label/mean 0.5\n",
            "average_loss 0.69237834\n",
            "auc_precision_recall 0.56318784\n",
            "accuracy 0.52644\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ew3kwGM-LS9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A Final Word\n",
        "\n",
        "We may have gotten a DNN solution with an embedding that was better than our original linear model, but the linear model was also pretty good and was quite a bit faster to train. Linear models train more quickly because they do not have nearly as many parameters to update or layers to backprop through.\n",
        "\n",
        "In some applications, the speed of linear models may be a game changer, or linear models may be perfectly sufficient from a quality standpoint. In other areas, the additional model complexity and capacity provided by DNNs might be more important. When defining your model architecture, remember to explore your problem sufficiently so that you know which space you're in."
      ]
    },
    {
      "metadata": {
        "id": "9MquXy9zLS9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### *Optional Discussion:* Trade-offs between `embedding_column` and `indicator_column`\n",
        "\n",
        "Conceptually when training a `LinearClassifier` or a `DNNClassifier`, there is an adapter needed to use a sparse column. TF provides two options: `embedding_column` or `indicator_column`.\n",
        "\n",
        "When training a LinearClassifier (as in **Task 1**), an `embedding_column` in used under the hood. As seen in **Task 2**, when training a `DNNClassifier`, you must explicitly choose either `embedding_column` or `indicator_column`. This section discusses the distinction between the two, and the trade-offs of using one over the other, by looking at a simple example."
      ]
    },
    {
      "metadata": {
        "id": "M_3XuZ_LLS9C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Suppose we have sparse data containing the values `\"great\"`, `\"beautiful\"`, `\"excellent\"`. Since the vocabulary size we're using here is $V = 50$, each unit (neuron) in the first layer will have 50 weights. We denote the number of terms in a sparse input using $s$. So for this example sparse data, $s = 3$. For an input layer with $V$ possible values, a hidden layer with $d$ units needs to do a vector-matrix multiply: $(1 \\times V) * (V \\times d)$.  This has $O(V * d)$ computational cost. Note that this cost is proportional to the number of weights in that hidden layer and independent of $s$.\n",
        "\n",
        "If the inputs are one-hot encoded (a Boolean vector of length $V$ with a 1 for the terms present and a 0 for the rest) using an [`indicator_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column), this means multiplying and adding a lot of zeros."
      ]
    },
    {
      "metadata": {
        "id": "I7mR4Wa2LS9C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When we achieve the exact same results by using an [`embedding_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) of size $d$, we look up and add up just the embeddings corresponding to the three features present in our example input of \"`great`\", \"`beautiful`\", \"`excellent`\": $(1 \\times d) + (1 \\times d) + (1 \\times d)$. Since the weights for the features that are absent are multiplied by zero in the vector-matrix multiply, they do not contribute to the result. Weights for the features that are present are multiplied by 1 in the vector-matrix multiply. Thus, adding the weights obtained via the embedding lookup will lead to the same result as in the vector-matrix-multiply.\n",
        "\n",
        "When using an embedding, computing the embedding lookup is an $O(s * d)$ computation, which is computationally much more efficient than the $O(V * d)$ cost for the `indicator_column` in sparse data for which $s$ is much smaller than $V$. (Remember, these embeddings are being learned. In any given training iteration it is the current weights that are being looked up.)"
      ]
    },
    {
      "metadata": {
        "id": "etZ9qf0kLS9D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we saw in **Task 3**, by using an `embedding_column` in training the `DNNClassifier`, our model learns a low-dimensional representation for the features, where the dot product defines a similarity metric tailored to the desired task. In this example, terms that are used similarly in the context of movie reviews (e.g., `\"great\"` and `\"excellent\"`) will be closer to each other the embedding space (i.e., have a large dot product), and terms that are dissimilar (e.g., `\"great\"` and `\"bad\"`) will be farther away from each other in the embedding space (i.e., have a small dot product)."
      ]
    }
  ]
}